{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sampling and the Central Limit Theorem\n",
    "\n",
    "![sample](https://media.giphy.com/media/OsOP6zRwxrnji/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Objectives\n",
    "\n",
    "\n",
    "By the end of this lesson students will be able to:\n",
    "\n",
    "1. Differentiate between the following terms: \n",
    "    - descriptive/inferential statistics \n",
    "    - population/sample\n",
    "    - paramater/statistic\n",
    "    - sample distribution/sampling distribution\n",
    "2. Define and calculate standard error\n",
    "3. Use Numpy to randomly sample a distribution\n",
    "4. Describe the central limit theorem and connect it to our knowledge of distributions and sampling.\n",
    "5. Construct confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability vs Statistics\n",
    "- Probability starts with known probabilities and obtains **how probable any particular observation would be**\n",
    "- Statistics works the other way around. Start with and observations (data) and **try to determine its probability**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive vs Inferential Statistics\n",
    "- Descriptive Statistics\n",
    "   > simply describe what is observed. The average height of a high school football team can be directly calculated by measuring all of the current players height.\n",
    "- Inferential statistics \n",
    "    > try to say something general about a larger group of subjects than those we have measured. For example, we would be doing inferential statistics if we wanted to know about the average height of all high school football teams.\n",
    "    - To put it another way, statistical inference is the process by which we take observations of a subset of a group and generalize to the whole group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Population Inference\n",
    "\n",
    "The mayor's office has hired Flatiron Data Science Immersive students to determine a way to fix traffic congestion. A good starting point is to determine what proportion of the population of DC owns a car.\n",
    "\n",
    "![traffic](https://media.giphy.com/media/3orieWY8RCodjD4qqs/giphy.gif)\n",
    "\n",
    "In order for us to make any determinations about a population, we must first get information about it.\n",
    "\n",
    "Because it's usually completely impractical to get data about *everyone* in a population, we must take a sample.\n",
    "\n",
    "## Key Terms\n",
    " - the entire group is known as the **population**  \n",
    " - the subset is a known as the **sample**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pop](./img/sample_pop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We would use samples if the population is:\n",
    "    - Too big to enumerate\n",
    "    - too difficult/time consuming or expensive to sample in its entirety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random sampling is not easy to do**  \n",
    "Continuing our DC car example, how would we take a sample? \n",
    "\n",
    "Here are two strategies we might employ:\n",
    "\n",
    "* Stand outside of Flatiron at 12 pm and ask random people until *n* responses\n",
    "\n",
    "\n",
    "* Go to a randomly assigned street corner and at a random time and ask *n* people if they own a car\n",
    "\n",
    "Which strikes you as better?\n",
    "\n",
    "What do we want our sample to look like?\n",
    "\n",
    "In particular, what relationship do we want between the sample and the population? What steps can we take to improve our odds of success in achieving this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "![talk amongst yourselves](https://media.giphy.com/media/l2SpQRuCQzY1RXHqM/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first way of sampling is considered a convenience sample.\n",
    "You are going about collection in a non-random manner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Conditions\n",
    "\n",
    "1. The sampled observations must be independent\n",
    "    - The sampling method must be random  \n",
    "\n",
    "\n",
    "2. Sample size distribution:\n",
    "    - The more skewed the sample the larger samples we need. \n",
    "    - n > 30 is considered a large enough sample unless there is extreme skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population v Sample Terminology\n",
    "Characteristics of populations are called **parameters**\n",
    "\n",
    "Characteristics of a sample are called **statistics**\n",
    "\n",
    "A sample statistic is a **point estimate** of the population parameter\n",
    "\n",
    "![imgsample](./img/sample_stats.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simulation to Reinforce Our Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a population of systolic blood pressure of adult males in DC, assuming a mean of 114 mmHg with a standard deviation of 11 mmHg.  We will also assume the adult male population to be 1.5 million. \n",
    "\n",
    "It is impossible to measure the systolic blood pressure of every man in DC, but let's assume multiple investigations have led to the conclusion numbers above. These are therefore estimators of the population parameter.\n",
    "\n",
    "$\\Large\\hat\\mu = 114$  \n",
    "$\\Large\\hat\\sigma = 11$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pop_size = int(1.5*10**6)\n",
    "# Use numpy to generate a normal distribution with the paramters above\n",
    "pop = np.random.normal(loc=114, scale=11, size=pop_size)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.kdeplot(pop, ax=ax, shade=True)\n",
    "ax.set_title('Distribution of Adult Male Systolic Blood Pressure')\n",
    "ax.set_xlabel('Systolic BP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's imagine we want to check whether the above numbers are correct.  We develop an effective manner of random sampling. Our sample size will be 40.\n",
    "\n",
    "Below, we will simulate with numpy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 40\n",
    "sample = np.random.choice(pop, sample_size)\n",
    "\n",
    "# We can look at the distribution of the values in the sample.\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.distplot(sample, ax=ax, bins=15)\n",
    "ax.set_title('Sample Distribution of Systolic BP Measurements')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then calculate the sample statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Sample mean: {sample.mean()}')\n",
    "print(f'Sample standard deviation: {sample.std()}')\n",
    "print(f'Sample median: {np.median(sample)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we repeated this process, taking samples of the population repeatedly, we would get an array of sample statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 1000\n",
    "sample_size = 40\n",
    "sample_stats = []\n",
    "\n",
    "for _ in range(number_of_samples):\n",
    "    sample = np.random.choice(pop, sample_size)\n",
    "    # collect the mean of each of the 1000 samples in sample stats\n",
    "    sample_stats.append(sample.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection of sample stats represents our __sampling distribution__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(sorted(sample_stats), bins=20)\n",
    "ax.set_title('Sampling Distribution\\n of Systolic BP')\n",
    "ax.set_xlabel(\"Systolic Blood Pressure\")\n",
    "ax.set_ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting property of this sampling distribution:\n",
    "    \n",
    " - As we continue to sample, the mean of the sampling distribution gets closer and closer to the population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standard Error of the Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard error of the mean is the standard deviation of the sampling distribution.\n",
    "The issue is that a sample is not an exact replica of the population. We need to account for that fact in order to make our estimate of the $\\mu$ value possible. Let's break it down:\n",
    "\n",
    "**Population sigma** <br/>\n",
    "\n",
    "$\\large\\sigma _{x} = \\frac{\\sigma }{\\sqrt{n}}$\n",
    "\n",
    "* $ \\sigma _{x}$ = standard error of $\\bar{x} $\n",
    "* $ \\sigma $ = standard deviation of population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the standard error of the mean for systolic blood pressure example with known mean and standard deviation, assuming a sample size of 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**What if we do not know the population sigma?**<br>\n",
    "If we do not know the population standard deviation, we can approximate it by using the sample standard deviation.\n",
    "\n",
    "$\\large\\sigma _{x} ≈ \\frac{S}{\\sqrt{n}}$\n",
    "\n",
    "* S = sample standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Sample size impact on standard error of mean**<br>\n",
    "\n",
    "How should sample size influence standard error of the mean?\n",
    "\n",
    "It will get *smaller* as sample size *increases*\n",
    "\n",
    "![error](./img/diminishing_error.png)  \n",
    "Important implication: The Standard Error of the mean remains the same as long as the population standard deviation is known and sample size remains the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_error(distribution, largest_sample_size, population_std=None):\n",
    "    \n",
    "    '''\n",
    "    Calculate the standard errors for a range of sample sizes\n",
    "    to demonstrate how standard error decreases when sample \n",
    "    size increases.\n",
    "    '''\n",
    " \n",
    "    std_errors = {}\n",
    "    \n",
    "    for sample_size in range(50,largest_sample_size+1):\n",
    "        sample = np.random.choice(distribution, size=sample_size, replace=True)\n",
    "        # Standard error with sample distribution standard deviation \n",
    "        # in place of population\n",
    "        if population_std == None:\n",
    "            std_err = np.std(sample)/np.sqrt(sample_size)\n",
    "            std_errors[sample_size] = std_err\n",
    "        \n",
    "        else:\n",
    "            std_err = population_std/np.sqrt(sample_size)\n",
    "            std_errors[sample_size] = std_err\n",
    "        \n",
    "    return std_errors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_errors = standard_error(pop, 1000)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.scatterplot(list(std_errors.keys()), list(std_errors.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_errors = standard_error(pop, 1000, population_std=114)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.scatterplot(list(std_errors.keys()), list(std_errors.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn!\n",
    "\n",
    "Word Exercise:\n",
    "\n",
    "Put the variables in the correct place.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "var_1 = 'population'\n",
    "var_2 = 'sample'\n",
    "var_3 = 'point estimate'\n",
    "var_4 = 'statistic'\n",
    "var_5 = 'parameter'\n",
    "var_6 = 'sampling'\n",
    "\n",
    "\n",
    "print(f\"\"\"We sampled 40 bee hives and calcuted the mean colony population \n",
    "          to be 75,690 bees. 75,690 is a {} of the population paramter\\n\"\"\")\n",
    "\n",
    "print(f\"\"\"We repeatedly sample 40 people at random from DC and \n",
    "        measure their heart rate,then calculate the mean of each sample. \n",
    "        We call the plot of this collection of statistics\n",
    "        the {} distribution.\n",
    "        \"\"\")\n",
    "\n",
    "print(f\"\"\"There are exactly 58 Javan Rhino's left in the wild. \n",
    "        Their mean length has been measured accurately at 5 feet.\n",
    "        This mean length is considered a population {}. \n",
    "        \"\"\")\n",
    "\n",
    "print(f\"\"\"If we plot a histogram of individual pistil lengths \n",
    "      measured on 50 hibiscus flowers, we would be plotting the distribution \n",
    "      of an attribute of our {} of hibiscus flowers. \n",
    "        \"\"\")\n",
    "\n",
    "print(f\"\"\"Since every restaurant in DC is required by law to register\n",
    "        with the city, we can accurately count the number of active pizza restaurants\n",
    "         operating right now.  This group represents the {} of actively \n",
    "        operating, registered pizza restaurants in DC.\n",
    "    \"\"\")\n",
    "\n",
    "print(f\"\"\"The mean number of hourly hits to Jelle's Marble Racing website \n",
    "            randomly sampled across a seven day period represents a sample\n",
    "            {}.\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Use numpy to randomly sample a distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we have different sample scenarios.  Each group will code out the following: \n",
    "\n",
    "You are given a \"population\" to sample from based on the type of distribution.\n",
    "\n",
    "1. Take a random sample of size n, where n > 30, from the population and calculate the mean of that population.\n",
    "\n",
    "2. Repeat the sample n numbers of times (n = 1000). \n",
    "\n",
    "3. Plot the sampling distribution\n",
    "\n",
    "4.  Discuss with your group how the sampling distribution differs from the population distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 1:\n",
    "\n",
    "A bowler on the PBA rolls a strike 60% of the time. The population strikes of all games ever bowled is stored in in the population variable below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = np.random.binomial(12, .6, 10000)\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(range(0,12), np.unique(population, return_counts=True)[0])\n",
    "ax.set_title('Strikes Per Game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 2:\n",
    "\n",
    "Stored in the variable below is the number of pieces of mail that arrive per week at your door for each of the 4500 weeks in your life.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_population = np.random.poisson(3, 4500)\n",
    "counts = np.unique(mail_population, return_counts=True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(np.unique(counts[0]), counts[1])\n",
    "ax.set_title('Distribution of Pieces of Mail/Week')\n",
    "ax.set_xlabel(\"Pieces of Mail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What we just illustrated above is that if we take repeated samples of a population, **the sampling distribution of sample means will approximate to a normal distribution**, no matter the underlying distribution!  This is called **The Central Limit Theorem**\n",
    "\n",
    "\n",
    "## $E(\\bar{x_{n}}) = \\mu$\n",
    "\n",
    "as n --> \"large\"\n",
    "\n",
    "[Seeing Theory](https://seeing-theory.brown.edu/probability-distributions/index.html)\n",
    "\n",
    "[good video demonstration](https://www.youtube.com/watch?v=jvoxEYmQHNM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at an example taken from the ubiquitous Iris dataset. This histogram represents the distributions of sepal length:\n",
    "\n",
    "\n",
    "![probgif](./img/probability-basics.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/tentotheminus9/central-limit-theorem-animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will see in hypothesis testing, pairing this theorem with the Empirical rule will be very powerful.\n",
    "\n",
    "![empirical](img/empirical_rule.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing that any sampling distribtion, no matter the underlying population distribution, will approach normality, we will be able to judge, given the empirical rule, how rare a given sample statistic is.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals\n",
    "\n",
    "\n",
    "A point estimate `x_bar`, of the mean, provides a single plausible value for a parameter. However, as we have seen, a point estimate is rarely perfect; usually there is some error in the estimate. That is why we have suggested using the standard error as a measure of its variability.\n",
    "\n",
    "Instead of that, a next logical step would be to provide a __plausible range of values__ for the parameter. A plausible range of values for the sample parameter is called a __confidence interval.__\n",
    "\n",
    "<img src = \"./img/margin_of_error.png\" width = 450 />\n",
    "\n",
    "Point estimate +/- margin of error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will deal mostly with confidence intervals for the statistics `mean`. We can create CI for other statistics too but this will require more advanced tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KEY POINT** : Our level of confidence that if we obtained a sample of equal size, our sample interval would contain the population mean.\n",
    "\n",
    " - This implies that there is an element of chance whether this interval will contain the true mean or not. In fact, when we calculate 95% confidence intervals, we should expect for every 20 samples and 20 confidence intervals created from these samples, one of them might miss the true parameter.\n",
    "\n",
    "Let's understand this better using a [visual display](https://seeing-theory.brown.edu/frequentist-inference/index.html#section2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Principles in the Construction of Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Our point estimate is the most plausible value of the parameter, so it makes sense to build the confidence interval around the point estimate.\n",
    "\n",
    " - The plausability of a range of values can be defined from the sampling distribution of the estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central Limit Theorem Recap:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a population with a mean $\\mu$ and a variance $\\sigma^{2}$, the sampling distribution of the mean approaches a normal distribution with a mean of $\\mu$ and standard deviation of $\\sqrt{\\frac{\\sigma^{2}}{n}}$ as n, the sample size, increases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__\n",
    "\n",
    "SE  = $\\sqrt{\\frac{\\sigma^{2}}{n}}$ will be called the standard error of the mean. We usually denote it with `SE`. Note that standard error of the mean is actually standard deviation of the sampling distribution of the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Central Limit Theorem with Respect to Different Population Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import expon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def central_limit_plot(dist_name, population_size, sample_size, num_samples):\n",
    "    \"\"\"\n",
    "    This function plots the original population distribution and\n",
    "    the sampling distribution of the mean derived from this population\n",
    "    \"\"\"\n",
    "    if dist_name == \"uniform\":\n",
    "        distribution =uniform.rvs(size = population_size)\n",
    "        mu, sigma = uniform.stats(moments = 'mv')\n",
    "        sampling_mean_distribution = []\n",
    "        for i in range(num_samples):\n",
    "            sample = uniform.rvs(size = sample_size)\n",
    "            sampling_mean_distribution.append(sample.mean())\n",
    "    if dist_name == \"exponential\":\n",
    "        distribution =expon.rvs(size = population_size)\n",
    "        mu, sigma = expon.stats(moments = 'mv')\n",
    "        sampling_mean_distribution = []\n",
    "        for i in range(num_samples):\n",
    "            sample = expon.rvs(size = sample_size)\n",
    "            sampling_mean_distribution.append(sample.mean())\n",
    "    if dist_name == \"poisson\":\n",
    "        distribution =poisson.rvs(mu =math.e, size = population_size)\n",
    "        mu, sigma = poisson.stats(mu = math.e, moments = 'mv')\n",
    "        sampling_mean_distribution = []\n",
    "        for i in range(num_samples):\n",
    "            sample = poisson.rvs(mu = math.e, size = sample_size)\n",
    "            sampling_mean_distribution.append(sample.mean())\n",
    "    sampling_mu = np.mean(sampling_mean_distribution)\n",
    "    empirical_standard_error = np.std(sampling_mean_distribution)\n",
    "    se = np.sqrt(sigma/sample_size)\n",
    "    \n",
    "    plt.figure(figsize = (10, 8))\n",
    "    plt.subplot(1,2,1).hist(distribution)\n",
    "    plt.title(\"%s Distribution: $\\mu$ =%.2f std: %.2f\"%(dist_name,mu,sigma))\n",
    "    plt.subplot(1,2,2).hist(sampling_mean_distribution)\n",
    "    plt.axvline(x = np.mean(sampling_mean_distribution), \n",
    "                color = 'yellow',\n",
    "                label=  \"$\\mu$= %.2f\"%sampling_mu)\n",
    "    plt.axvline(x = mu - empirical_standard_error, color = 'red', linestyle = \"--\", label = \"Emprical SE: %.2f\"%empirical_standard_error)\n",
    "    plt.axvline(x = mu + empirical_standard_error, color = 'red', linestyle = \"--\", label = \"SE: %.2f\"%se)\n",
    "    plt.title(\"Sampling distribution of the mean\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_limit_plot(dist_name = \"uniform\", population_size= 5000, sample_size = 100, num_samples= 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Confidence Intervals with Heart data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's read in our heart data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "heart = pd.read_csv('./data/heart.csv')\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the 95% confidence interval around the mean of cholesterol.  Remember the formula for confidence intervals is \n",
    "\n",
    "![](https://lh3.googleusercontent.com/proxy/VIqT8n9eMSulOI5VSGQzoj6o06bgjj1fc2NzA9kVCkvP0fS9wk8k4wGsvYwEmPrn_jKMTUKW2qY72eaY2hL2tv70tFACrRhzqiqtAV_Z62VrBfnnNLTSEOlh06j29J9N1JPe5zUQ5vE0w50ksIRNFjyPf_I70NCeFl9p3wQ)\n",
    "\n",
    "And here is a quick table of confidence factors for each type of CI.\n",
    "\n",
    "![](./img/Confidence_factors.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bar = heart.chol.mean()\n",
    "\n",
    "n = len(heart)\n",
    "\n",
    "sigma = heart.chol.std()\n",
    "\n",
    "se = np.sqrt(sigma**2/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI = [x_bar - 1.96*se, x_bar + 1.96*se]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The confidence interval around the mean of cholesterol indicates that there is a 95% chance that the true mean of cholesterol is between 242 and 249."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn!\n",
    "\n",
    "Calculate the 99% CI around the mean resting blood pressure (`trestbps`).  Interpret the CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
